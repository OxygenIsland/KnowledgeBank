## 1. 张量
$n$维数组，也称为*张量*（tensor）。无论使用哪个深度学习框架，*张量类*（在MXNet中为`ndarray`，在PyTorch和TensorFlow中为`Tensor`）都与Numpy的`ndarray`类似。但深度学习框架又比Numpy的`ndarray`多一些重要功能：首先，GPU很好地支持加速计算，而NumPy仅支持CPU计算；其次，张量类支持自动微分。这些功能使得张量类更适合深度学习。

(**首先，我们导入`torch`。请注意，虽然它被称为PyTorch，但是代码中使用`torch`而不是`pytorch`。**)
```jupyter
import torch
print("一维向量")
x = torch.arange(12) 
x
print("一维向量的shape")
x.shape()
print("一维向量的numel")
x.numel()

```

**张量表示一个由数值组成的数组，这个数组可能有多个维度**。

具有一个轴的张量对应数学上的*向量*（vector）；具有两个轴的张量对应数学上的*矩阵*（matrix）；具有两个轴以上的张量没有特殊的数学名称。
### 1.1 arange
使用 `arange` 创建一个行向量 `x`。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 *元素*（element）。例如，张量 `x` 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。
```python
x = torch.arange(12)
# tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
```
- `torch.arange()` 用于创建一个包含一定范围内的连续数值的张量。
- 它类似于 Python 中的 `range()` 函数，但返回的是一个 PyTorch 张量，而不是一个列表。
- **常见用法**：
    `torch.arange(start, end, step)`
    - `start`：序列的起始值（默认为 0）。
    - `end`：序列的结束值（不包括 `end`）。
    - `step`：序列中每两个值之间的步长（默认为 1）。
### 1.2 shape
**可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的 *形状* 和 *张量* 中元素的总数。**
```python
x.shape
# torch.Size([12])
```
如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。因为这里在处理的是一个向量，所以它的`shape`与它的`size`相同。
### 1.3 numel（number of elements）
numel()可以直接返回**int类型的元素个数**
```python
x.numel()
# 12
```
**要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数。**
例如，可以把张量`x`从形状为（12,）的行向量转换为形状为（3,4）的矩阵。这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。虽然张量的形状发生了改变，但其元素值并没有变，张量的大小也不会改变。
```python
X = x.reshape(3, 4)
X
# tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])
```
我们不需要通过手动指定每个维度来改变形状。也就是说，如果我们的目标形状是（高度,宽度），那么在知道宽度后，高度会被自动计算得出，不必我们自己做除法。在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。==幸运的是，我们可以通过`-1`来调用此自动计算出维度的功能。==即我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。
有时，我们希望**使用全0、全1、其他常量，或者从特定分布中随机采样的数字**来初始化矩阵。我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：
```python
torch.zeros((2, 3, 4))
```
同样，我们可以创建一个形状为 `(2,3,4)` 的张量，其中所有元素都设置为1。代码如下：
```python
torch.ones((2, 3, 4))
```
有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。以下代码创建一个形状为（3,4）的张量。其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。
```python
torch.randn(3, 4)
```
我们还可以通过提供包含数值的 Python 列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。在这里，最外层的列表对应于轴0，内层的列表对应于轴1。
```python
torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
```
## 2 运算符
我们的兴趣不仅限于读取数据和写入数据。我们想在这些数据上执行数学运算，其中最简单且最有用的操作是 *按元素*（elementwise）运算。它们将标准标量运算符应用于数组的每个元素。对于将两个数组作为输入的函数，按元素运算将二元运算符应用于两个数组中的每对位置对应的元素。我们可以基于任何从标量到标量的函数来创建 按元素函数。

在数学表示法中，我们将通过符号 $f \colon \mathbb{R} \to \mathbb{R}$ 来表示*一元*标量运算符（只接收一个输入）。这意味着该函数从任何实数（R）映射到另一个实数。同样，我们通过符号 $f \colon \mathbb{R},\mathbb{R} \to \mathbb{R}$ 表示*二元*标量运算符，这意味着该函数接收两个输入，并产生一个输出。给定同一形状的任意两个向量 u 和 v 和二元运算符 f，我们可以得到向量 $c=F(u,v)$。具体计算方法是 $c_i \leftarrow f(u_i, v_i)$ ，其中 ci、ui 和 vi 分别是向量 c、u 和 v 中的元素。在这里，我们通过将标量函数升级为按元素向量运算来生成向量值 $F \colon \mathbb{R}^d, \mathbb{R}^d \to \mathbb{R}^d$ 。

对于任意具有相同形状的张量，常见的标准算术运算符（`+`、`-`、`*`、`/` 和 `**`）都可以被升级为按元素运算。我们可以在同一形状的任意两个张量上调用按元素操作。在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。
```python
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算
```

```shell
(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))
```
“按元素”方式可以应用更多的计算，包括像求幂这样的一元运算符。
```python
torch.exp(x)  #计算输入张量 `x` 中每个元素的自然指数函数的操作
```
具体来说，会对 `x` 中的每个元素进行如下运算：
$$\text{output}[i] = e^{x[i]}$$
我们也可以把多个张量*连结*（concatenate）在一起，把它们端对端地叠起来形成一个更大的张量。我们只需要提供张量列表，并给出沿哪个轴连结。下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。我们可以看到，第一个输出张量的轴-0长度（6）是两个输入张量轴-0长度的总和（3+3）；第二个输出张量的轴-1长度（8）是两个输入张量轴-1长度的总和（4+4）。
```python
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)
```

```shell
(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]]),
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))
```
合并两个张量容易搞混的是合并条件、合并后 tensor 的 size：
1. 合并条件，合并两个 n 维 tensor，除了要合并的那个轴的 size 可以不相同，甚于其他维度的 size 要相同
2. 合并之后的 shape，合并的那个轴的 size 是两个 tensor 对应轴 size 相加，其他轴的 size 不变

有时，我们想通过 *逻辑运算符* 构建二元张量。以 `X == Y` 为例： 对于每个位置，如果 `X` 和 `Y` 在该位置相等，则新张量中相应项的值为1。这意味着逻辑语句 `X == Y` 在该位置处为真，否则该位置为0。
```python
X == Y
```

```shell
tensor([[False,  True, False,  True],
        [False, False, False, False],
        [False, False, False, False]])
```
对张量中的所有元素进行求和，会产生一个单元素张量。
```python
X.sum()
```

```shell
tensor(66.)
```
## 3广播机制
在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。在某些情况下，即使形状不同，我们仍然可以通过调用 _广播机制_（broadcasting mechanism）来执行按元素操作。这种机制的工作方式如下：
1. 通过适当==复制元素==来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
2. 对生成的数组执行按元素操作。
在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子：
```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
a, b
```

```shell
(tensor([[0],
         [1],
         [2]]),
 tensor([[0, 1]]))
```
由于 `a` 和 `b` 分别是3×1和1×2矩阵，如果让它们相加，它们的形状不匹配。我们将两个矩阵_广播_为一个更大的3×2矩阵，如下所示：矩阵 `a` 将===复制===列，矩阵 `b` 将复制行，然后再按元素相加。
```python
a + b
```

```shell
tensor([[0, 1],
        [1, 2],
        [2, 3]])
```
## 4索引和切片
就像在任何其他 Python 数组中一样，张量中的元素可以通过索引访问。与任何 Python 数组一样：第一个元素的索引是0，最后一个元素索引是-1；可以指定范围以包含第一个元素和最后一个之前的元素。详情点击 [[Python中数组切片的用法|这里]]

如下所示，我们可以用 `[-1]` 选择最后一个元素，可以用 `[1:3]` 选择第二个和第三个元素：
```python
X[-1], X[1:3]  # 在X 张量的第一个维度上进行切片，其他维度都要
```

```shell
(tensor([ 8.,  9., 10., 11.]),
 tensor([[ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.]]))
```