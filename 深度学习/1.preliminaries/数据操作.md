# 1. 张量
$n$维数组，也称为*张量*（tensor）。无论使用哪个深度学习框架，*张量类*（在MXNet中为`ndarray`，在PyTorch和TensorFlow中为`Tensor`）都与Numpy的`ndarray`类似。但深度学习框架又比Numpy的`ndarray`多一些重要功能：首先，GPU很好地支持加速计算，而NumPy仅支持CPU计算；其次，张量类支持自动微分。这些功能使得张量类更适合深度学习。

(**首先，我们导入`torch`。请注意，虽然它被称为PyTorch，但是代码中使用`torch`而不是`pytorch`。**)
```jupyter
import torch
print("一维向量")
x = torch.arange(12) 
x
print("一维向量的shape")
x.shape()
print("一维向量的numel")
x.numel()

```


**张量表示一个由数值组成的数组，这个数组可能有多个维度**。

具有一个轴的张量对应数学上的*向量*（vector）；具有两个轴的张量对应数学上的*矩阵*（matrix）；具有两个轴以上的张量没有特殊的数学名称。
## 1.1 arange
使用 `arange` 创建一个行向量 `x`。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 *元素*（element）。例如，张量 `x` 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。
```python
x = torch.arange(12)
# tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
```

## 1.2 shape
**可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的 *形状* 和 *张量* 中元素的总数。**
```python
x.shape
# torch.Size([12])
```
如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。因为这里在处理的是一个向量，所以它的`shape`与它的`size`相同。
# 1.3 numel（number of elements）
numel()可以直接返回**int类型的元素个数**
```python
x.numel()
# 12
```
**要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数。**
例如，可以把张量`x`从形状为（12,）的行向量转换为形状为（3,4）的矩阵。这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。虽然张量的形状发生了改变，但其元素值并没有变，张量的大小也不会改变。
```python
X = x.reshape(3, 4)
X
# tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])
```
我们不需要通过手动指定每个维度来改变形状。也就是说，如果我们的目标形状是（高度,宽度），那么在知道宽度后，高度会被自动计算得出，不必我们自己做除法。在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。==幸运的是，我们可以通过`-1`来调用此自动计算出维度的功能。==即我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。
有时，我们希望**使用全0、全1、其他常量，或者从特定分布中随机采样的数字**来初始化矩阵。我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：
```python
torch.zeros((2, 3, 4))
```
