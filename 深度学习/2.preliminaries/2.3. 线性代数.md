## 2.3.1.标量
如果你曾经在餐厅支付餐费，那么应该已经知道一些基本的线性代数，比如在数字间相加或相乘。例如，北京的温度为 $52^{\circ}F$（华氏度，除摄氏度外的另一种温度计量单位)。严格来说，仅包含一个数值被称为*标量*（scalar）。如果要将此华氏度值转换为更常用的摄氏度，则可以计算表达式 $c=\frac{5}{9}(f-32)$，并将 $f$ 赋为 $52$。在此等式中，每一项（$5$、$9$ 和 $32$）都是标量值。符号 $c$ 和 $f$ 称为*变量*（variable），它们表示未知的标量值。

本书采用了数学表示法，其中标量变量由普通小写字母表示（例如，$x$、$y$ 和 $z$）。本书用 $\mathbb{R}$ 表示所有（连续）*实数*  标量的空间，之后将严格定义*空间*（space）是什么，但现在只要记住表达式 $x\in\mathbb{R}$ 是表示 $x$ 是一个实值标量的正式形式。符号 $\in$ 称为“属于”，它表示“是集合中的成员”。例如 $x, y \in \{0,1\}$ 可以用来表明 $x$ 和 $y$ 是值只能为 $0$ 或 $1$ 的数字。
(**标量由只有一个元素的张量表示**)。
下面的代码将实例化两个标量，并执行一些熟悉的算术运算，即加法、乘法、除法和指数。
```python
import torch
x = torch.tensor(3.0)
y = torch.tensor(2.0)
x + y, x * y, x / y, x**y
```
`(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))`

## 2.3.2 向量
**向量可以被视为标量值组成的列表**
这些标量值被称为向量的*元素*（element）或*分量*（component）。当向量表示数据集中的样本时，它们的值具有一定的现实意义。例如，如果我们正在训练一个模型来预测贷款违约风险，可能会将每个申请人与一个向量相关联，其分量与其收入、工作年限、过往违约次数和其他因素相对应。如果我们正在研究医院患者可能面临的心脏病发作风险，可能会用一个向量来表示每个患者，其分量为最近的生命体征、胆固醇水平、每天运动时间等。在数学表示法中，向量通常记为粗体、小写的符号（例如，$\mathbf{x}$、$\mathbf{y}$ 和 $\mathbf{z})$）。
人们通过一维张量表示向量。一般来说，张量可以具有任意长度，取决于机器的内存限制。
```python
x = torch.arange(4)
x
```
`tensor([0, 1, 2, 3])`
我们可以使用下标来引用向量的任一元素，例如可以通过 $x_i$ 来引用第 i 个元素。注意，元素 $x_i$ 是一个标量，所以我们在引用它时不会加粗。大量文献认为列向量是向量的默认方向，在本书中也是如此。在数学中，向量 x 可以写为：
$$\mathbf{x} =\begin{bmatrix}x_{1}  \\x_{2}  \\ \vdots  \\x_{n}\end{bmatrix},$$
其中 $x_1,\ldots,x_n$ 是向量的元素。在代码中，我们(**通过张量的索引来访问任一元素**)。
```python
x[3]
```
`4`
### 2.3.2.1. 长度、维度和形状
向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。在数学表示法中，如果我们想说一个向量 x 由 n 个实值标量组成，可以将其表示为 x∈Rn。向量的长度通常称为向量的 *维度*（dimension）。
与普通的Python数组一样，我们可以通过调用Python的内置`len()`函数来访问张量的长度。
当用张量表示一个向量（只有一个轴）时，我们也可以通过 `.shape` 属性访问向量的长度。形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。对于只有一个轴的张量，形状只有一个元素。
```python
x.shape
```
`torch.Size([4])`
请注意，_维度_（dimension）这个词在不同上下文时往往会有不同的含义，这经常会使人感到困惑。为了清楚起见，我们在此明确一下： _向量_ 或 _轴_ 的维度被用来表示 _向量_ 或 _轴_ 的长度，即向量或轴的元素数量。然而，张量的维度用来表示张量具有的轴数。在这个意义上，张量的某个轴的维数就是这个轴的长度。
## 2.3.3. 矩阵
正如向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶。矩阵，我们通常用粗体、大写字母来表示 （例如，$\mathbf{X}$、$\mathbf{Y}$ 和 $\mathbf{Z}$），在代码中表示为具有两个轴的张量。
数学表示法使用 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 来表示矩阵 $\mathbf{A}$，其由 $m$ 行和 $n$ 列的实值标量组成。我们可以将任意矩阵$\mathbf{A} \in \mathbb{R}^{m \times n}$视为一个表格，其中每个元素$a_{ij}$属于第$i$行第$j$列：
$$\mathbf{A}=\begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \\ \end{bmatrix}.$$
对于任意$\mathbf{A} \in \mathbb{R}^{m \times n}$，$\mathbf{A}$的形状是（$m$,$n$）或$m \times n$。当矩阵具有相同数量的行和列时，其形状将变为正方形；因此，它被称为*方阵*（square matrix）。当调用函数来实例化张量时，我们可以**通过指定两个分量 $m$ 和 $n$ 来创建一个形状为 $m \times n$ 的矩阵**。
```python
A = torch.arange(20).reshape(5, 4)
A
```

```shell
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15],
        [16, 17, 18, 19]])
```
我们可以通过行索引（$i$）和列索引（$j$）来访问矩阵中的标量元素 $a_{ij}$，例如 $[\mathbf{A}]_{ij}$。如果没有给出矩阵 $\mathbf{A}$ 的标量元素，如在 :eqref: `eq_matrix_def` 那样，我们可以简单地使用矩阵 $\mathbf{A}$ 的小写字母索引下标 $a_{ij}$ 来引用 $[\mathbf{A}]_{ij}$。 为了表示起来简单，只有在必要时才会将逗号插入到单独的索引中，例如$a_{2,3j}$和$[\mathbf{A}]_{2i-1,3}$。当我们交换矩阵的行和列时，结果称为矩阵的*转置*（transpose）。通常用$\mathbf{a}^\top$来表示矩阵的转置，如果$\mathbf{B}=\mathbf{A}^\top$，则对于任意$i$和$j$，都有$b_{ij}=a_{ji}$。
因此，在 :eqref:`eq_matrix_def`中的转置是一个形状为$n \times m$的矩阵：

  

$$

\mathbf{A}^\top =

\begin{bmatrix}

    a_{11} & a_{21} & \dots  & a_{m1} \\

    a_{12} & a_{22} & \dots  & a_{m2} \\

    \vdots & \vdots & \ddots  & \vdots \\

    a_{1n} & a_{2n} & \dots  & a_{mn}

\end{bmatrix}.

$$

  

现在在代码中访问(**矩阵的转置**)。