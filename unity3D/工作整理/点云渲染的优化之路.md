---
title: "[[点云渲染的优化之路]]"
type: Permanent
status: ing
Creation Date: 2025-09-16 11:06
tags:
---
## 1、原始方案

点云数据解析（坐标系转换，计算密集；颜色处理）->分块处理->分帧处理->GameObject实例化->GPU对每个立方体进行处理（顶点处理、光栅化、片元着色、渲染管线）

CPU瓶颈
主线程阻塞: for (int i = 0; i < _pointCount; i++) 一次性处理所有点
GameObject风暴: 10万个点 = 10万个GameObject + 30万个组件
材质状态破坏: 每个立方体独立设置颜色，无法GPU批处理
每个立方体独立设置material.color，Unity无法合批
10万个点 = 10万个DrawCall
GPU性能严重浪费

GPU瓶颈
DrawCall爆炸: 每个GameObject一个DrawCall
几何数据冗余: 相同立方体数据重复传输

## 2、使用mesh api
Unity 的 Mesh API 允许开发者通过脚本来创建和修改网格 (Mesh) 的几何信息。网格是构成 3D 模型的基础，它包含了顶点、三角形、法线、UV坐标等数据。使用Mesh API进行优化，可以将大量GameObject替换为高效的Mesh渲染。
从概念上讲，一个 Mesh 对象主要由以下几部分数据组成：
- **顶点 (Vertices)**: 一个 Vector3 数组，定义了模型在 3D 空间中的所有顶点位置。[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFIArtHO9RZw32ULGSahOPu5Nu08VfYpiK3D5dvqLtupfAQQHbnJXG6acqYzH_cV_KZw9ZVAnHBbjT7QAU-qYT4HjpX_EjbYxTUEl0QAElhi8631fx2tudFlwx-_38-ZqTQ7qZBxA%3D%3D) 
- **三角形 (Triangles)**: 一个整数数组，通过引用顶点数组的索引来定义模型的面。数组中的每三个整数构成一个三角形。[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEnlfSdd2duLMr2MUDHGeoZp12e8v6cSMx-76_K5w3kctkUVFx3B45LJLCC2ZlH1BF3DWki2lZvFiAnOO-3rWJTY1FvREls9FV_6GcMh0wod5Vi5pNdxQ8PoeiQMnqcyemW7h5QO_kyUq433Ugbq29XsUVecBreoQ%3D%3D) 
- **UV 坐标 (UVs)**: 一个 Vector2 数组，用于将 2D 纹理贴图映射到 3D 模型的表面。
- **法线 (Normals)**: 一个 Vector3 数组，定义了每个顶点朝向的方向。这对于光照计算至关重要。
- **颜色 (Colors)**: 一个 Color 数组，可以为每个顶点指定颜色。

Unity 提供了两套用于操作网格的 API：[1](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEnlfSdd2duLMr2MUDHGeoZp12e8v6cSMx-76_K5w3kctkUVFx3B45LJLCC2ZlH1BF3DWki2lZvFiAnOO-3rWJTY1FvREls9FV_6GcMh0wod5Vi5pNdxQ8PoeiQMnqcyemW7h5QO_kyUq433Ugbq29XsUVecBreoQ%3D%3D) 
1. **简单 API**: 如 mesh.vertices, mesh.triangles 等。这些方法易于使用，并且包含了验证检查，以确保传入数据的有效性。[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFIArtHO9RZw32ULGSahOPu5Nu08VfYpiK3D5dvqLtupfAQQHbnJXG6acqYzH_cV_KZw9ZVAnHBbjT7QAU-qYT4HjpX_EjbYxTUEl0QAElhi8631fx2tudFlwx-_38-ZqTQ7qZBxA%3D%3D) 
2. **高级 API**: 如 SetVertexBufferParams, SetVertexBufferData 等。这套 API 旨在提供更高的性能，它允许直接写入网格数据，并跳过验证检查，适用于需要极致性能的高级用户。[2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFIArtHO9RZw32ULGSahOPu5Nu08VfYpiK3D5dvqLtupfAQQHbnJXG6acqYzH_cV_KZw9ZVAnHBbjT7QAU-qYT4HjpX_EjbYxTUEl0QAElhi8631fx2tudFlwx-_38-ZqTQ7qZBxA%3D%3D)[3](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFKp6PXFH5gCpEv8UwBU3zI-Q8XFnm3QQsw52yUXyGzXtoa-FZfG-4HnBkMqyNp4QjorZRK5dMj3cjnyrssTTJTfj185E_2tCXq7K-y-y2S7r_dJn-w6bXEpOTVsQnNtEqJbV4OwV7-) 在 Unity 2020.1 及之后版本，新的 MeshData API 甚至支持在多线程环境（通过 C# Jobs 和 Burst 编译器）中创建和修改网格，极大地提升了复杂网格生成的性能。[4](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQEaAVSupOuAX261rRuytvZV1QokoQNd-oBZFU_Euqj4_Z27PbgULv_VAKigo5c8OQsRf1JQKxgAaicoFsZXUx8xItq65nR13jYDgSjgci66cIWxnldCURbFI_Z0pEfO2FWJ6QHC9pgj)[5](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQH8s_G30czw9c_RkhDzjy93MLL1R8ljRkuHjibQP5jajjIOz1tDs30EnkP5wTxrCS7TAl0kpydjwXZnk6GDh367w8Us9Xb8WAwD1fFAKz2Y3xelQqlrIp43Ov-_sZydBlDhcxx6jG1kdRNKgsAnA2zU)

点云数据解析（坐标系转换，计算密集；颜色处理）->分批处理->批处理器渲染

Graphics.DrawMeshInstanced 是一个强大的底层渲染 API，它的核心作用是**使用 GPU 实例化 (GPU Instancing) 技术，通过一次绘制调用 (Draw Call) 来渲染成百上千个相同的网格副本**。[6](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQGOdm9hLNvoz-oxCyGeG4NtdjAGYsmjnkZ4cVjHhRK9TEDEdlIqXKxpdey107aD1XOgusuaRbYPywk-u5YMEABrsNYW4IvIx17xzQkxdi4L_Ca4IUkPrRrK_L-XKYZs7A55DuWdbgE80I5HfANbSRbFdWxQ8edF4QLneTPx4XRZnvh4PR0TtHoRW8hDeMXQiK_fltNZYhwF5Q%3D%3D) 

在常规的渲染流程中，每个独立的物体（GameObject）通常都需要一次单独的 Draw Call。CPU 需要准备每个物体的数据并通知 GPU 去渲染。当场景中有大量相同物体时（例如草地、森林、人群），CPU 的开销会变得非常巨大，导致性能瓶颈。[7](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFMT-hkmMUlZQSQ7l9zbk3T9VW3aEMBiS1nweiIZFVx6MXAi2zDxyB_knuHLowm9YZKA9KvIqAHZ9Y4SnOum3nBN4BpQp7tSyARWm8VPAG_EKOHUwceAQMXq-V5U0teYH778uHuccg463U76ce047ni07hNITQ%3D) 

GPU 实例化技术通过将所有相同网格的变换信息（位置、旋转、缩放）打包成一个数组，一次性发送给 GPU。然后，GPU 会利用其强大的并行处理能力，一次性将所有实例全部渲染出来。这样做极大地**减少了 Draw Call 数量**，从而显著降低了 CPU 的负担，是渲染大量重复物体时的关键优化手段。[7](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFMT-hkmMUlZQSQ7l9zbk3T9VW3aEMBiS1nweiIZFVx6MXAi2zDxyB_knuHLowm9YZKA9KvIqAHZ9Y4SnOum3nBN4BpQp7tSyARWm8VPAG_EKOHUwceAQMXq-V5U0teYH778uHuccg463U76ce047ni07hNITQ%3D)[8](https://www.google.com/url?sa=E&q=https%3A%2F%2Fvertexaisearch.cloud.google.com%2Fgrounding-api-redirect%2FAUZIYQFERv4DoXkuVyixJBBcWuh2-1nlmaqV30jyYNpOXkUJ1wkHsjcyXona7eAK_NQzWWX4AX7GazwXAAteThsD0fAGl3kuKcskPKyohnhGFRpOImbLCMQfMfTsAUA8lHMRkr6mQzqaDA%3D%3D) 

**CPU 串行解析数据 → CPU 分批打包实例数据 → GPU 并行渲染大量实例**

渲染的核心是分批处理。由于一次 DrawMeshInstanced 调用有实例数量上限（通常是 1023），代码以 _maxInstancesPerBatch 为步长遍历所有点。
1. **创建渲染代理**: CreateInstancedBatch 函数被调用。
    - 它创建一个新的 GameObject (batchObject) 来代表这个批次。
    - 关键一步：它添加了一个 PointCloudBatchRenderer 组件。
    - **数据流动**: Initialize 方法被调用，将这个批次的**立方体 Mesh**、**专用材质**、**变换矩阵数组 matrices** 和**颜色数组 colors** 全部传递并存储在 PointCloudBatchRenderer 实例中。

主要优化点
🚀 性能提升
DrawCall优化: 从10万个降低到约100个（每批1023个实例）
内存优化: 消除大量GameObject和组件创建
GPU利用: 充分利用GPU Instancing并行渲染能力
🔧 实现方式
GPU Instancing: 使用Graphics.DrawMeshInstanced批量渲染
MaterialPropertyBlock: 为每个实例设置独立颜色
分批处理: 解决GPU Instancing的1023实例限制
Mesh合并备选方案: 提供CreateMeshesWithCombining作为备选
📊 预期性能对比

指标	原实现	Mesh优化后	提升倍数
DrawCall	100,000	~100	1000x
内存使用	极高	低	10-50x
帧率	1-5 FPS	30-60 FPS	10-60x
CPU使用率	90%+	<20%	5x+

## 3、使用computerBuffer
点云数据解析（坐标系转换，计算密集；颜色处理）->cpu将点的信息传输到显存中->视锥体剔除->gpu执行渲染
- **CPU/GPU 流动路径**:
    1. **CPU 计算密集区**: 网络 byte[] → 解析为 List\<Vector3> (RAM) → 转换为 List\<Matrix4x4> (RAM)。
    2. **CPU → GPU 数据上传**: List\<Matrix4x4> (RAM) → positionInputBuffer (VRAM)。
    3. **GPU 内部流动**: positionInputBuffer → (Compute Shader 剔除) → positionOutputBuffer + argsBuffer (计数)。
    4. **GPU 内部渲染**: argsBuffer + positionOutputBuffer → 最终像素。


点云优化的演讲词

下面来讲一下DWRemote中点云的渲染方案。移动设备因为硬件上的一些限制，他的计算能力本来就有些紧张，那么面对点云这样比较庞大的数据，任何没有经过优化的数据访问都有可能造成线程阻塞，导致GPU空转。而且我们要渲染的点云数据不是一个静态的，它是要跟随环境变化而实时变化的，所以我们的点云数据是要从云端进行加载解析的，这也带来了一些额外的计算压力。那么目前行业内也有不少移动端点云渲染的解决方案，但是他们的目标是流畅渲染百万千万级的点云，所以他们的数据结构和渲染管线都太重了，这些方案的核心是‘如何用有限的资源去调度无限的数据’。而我们的问题是‘**如何用最少的资源，去渲染有限但实时变化的数据**’。因为DWRemote**不是一个专门的点云渲染器**。CPU除了要处理渲染，它还有更重要的任务：网络通信、解析机器人状态、响应用户UI操作、执行控制逻辑等等。渲染模块绝不能‘喧宾夺主’，把CPU资源吃干抹净，导致整个App失去响应。

我的思路很简单：彻底解放CPU。CPU忙啊，那渲染的事你就别管了。我把点云的解析、变换、剔除这些脏活累活，全部交给真正擅长并行计算的专家——GPU去做。

CPU只做一件事：从网络接收到原始的、压缩的二进制点云数据。然后，它不做任何解析，直接把数据扔给GPU。GPU拿到数据之后会做三件事，分别是数据解析、增量更新、视锥体剔除。
首先大量的GPU核心会同时工作将点云数据解析为一个个点的位置和颜色信息。
接下来我们要将点云的数据保存下来，这些数据是增量更新的基础，如果是第一次收到数据，那我们通过全量更新的管道来保存点云，如果已经不是第一次收到数据了，那我们就通过增量更新的管道来处理发生变化的那部分点云。如何对点云进行管理呢？客户端会和后端约定好数据结构，点云中的每个点都会有一个索引，从而去更新发生变化的点。
ok，无论我们前面通过哪个管道将点云保存下来以后，我们要对点云进行进一步的处理，我们要对GPU的性能进行进一步的节省，程序员都比较小气，不该花的钱，一分都花不了；不该花的性能，1kb也花不了。那么我们还能从哪里再扣一点呢？其实我们收到的点云数据往往是周围环境的一个整体数据，而用户不是每时每刻都想观察这个整体的数据，用户想看的是他感兴趣的那部分，用户会调节相机的视野来观察感兴趣的那部分，通过我们的视锥体剔除的计算，我们会将视野外的点都剔除掉，只渲染用户感兴趣的点云数据。
最后，我们通过间接渲染方式顺便把CPU的工作也减轻了，视锥体剔除计算完之后，GPU能做的事情就做完了，下一步的行动就要请示领导了。请示谁呢？请示CPU，CPU得知GPU完成工作后就开始计算总共有多少个点需要被渲染出来，计算完成之后，告诉GPU你需要渲染300个点，然后GPU去执行渲染指令。但是，cpu的这个计算工作也可以省掉，因为所有的计算都是GPU完成的，GPU对于需要渲染的点是心里有数的，所以CPU不需要计算，只需要说两个字，开始渲染，哦，是4个字，剩下的都交给GPU。

最终，我们的。。。
